# 3.1 实现选择 未校正

我们首先介绍拥塞控制机制面临的4个实现选择，以及TCP/IP 最后选择决策背后的设计逻辑。一些决策在当时的环境下看起来是“显而易见”的，但为了完整性——以及考虑到互联网持续发展意味着环境也在变化——审视所有选择是明智的。

## 3.1.1 中心化还是分布式

原则上来说，网络资源分配的第一个设计决策就是：采取集中式方法还是分布式方法？实际上，互联网的规模以及连接到互联网的组织的自主性，必然会导致采用分布式方法。确实，资源的分布式管理是互联网设计的明确目标，如Dave Clark所阐述。但是，理解这个默认决策很重要，原因有二。

_更多阅读：D. Clark,_ [_The Design Philosophy of the DARPA Internet Protocols_](https://dl.acm.org/doi/10.1145/52324.52336)_. ACM SIGCOMM, 1988._

* 互联网的拥塞控制方法是在其数百万个主机和路由器之间分布式实施的，我们可以合理地将它们视为以协作的方式来实现全局最优解。从这个角度看，存在一个共享的目标函数，所有元素都在执行一个分布式算法来优化该目标函数。本书中描述的各种机制只是定义了不同的目标函数，但是一直存在的挑战是，当多种不同的机制部署之后，如何考虑这些竞争的目标函数。
* 虽然对于整个互联网来说，采用中心化方法不太可行，但对于一个有限的范围来说，这种方法可能却是合适的。例如，一个逻辑上的中心化控制器可以收集关于网络链路和交换机状态的信息，计算出全局最优的分配方案，然后向终端用户建议（甚至限制）每个用户可用的容量。这种方法肯定受限于中心控制器响应网络变化的时间长短，但它已经成功应用于B4和SWAN这一类粗粒度资源分配的流量工程机制中。在粗粒度流量工程决策和细粒度拥塞控制决策之间，并没有明显的界限，但是对可用选项保持开放的态度是有好处的。

_更多阅读：S. Jain, et al._ [_B4: Experience with a Globally-Deployed Software Defined WAN_](https://cseweb.ucsd.edu/\~vahdat/papers/b4-sigcomm13.pdf)_. ACM SIGCOMM, August 2013._

中心化控制在数据中心内部已经被有效的应用起来。数据中心是拥塞控制问题的一个有趣的环境。首先，它的 RTT 非常低（指的是对于数据中心内服务器间的流量，而不是进出数据中心的流量）。其次，在许多情况下，可以将数据中心视为一个空白领域，因为不必与现有算法竞争所以可以提升尝试新方法的可能性。Fastpass 就是这样一种集中式方法的良好例证，它是 MIT 和 Facebook 研究人员合作开发的。

_更多阅读：J. Perry, et al._ [_Fastpass: A Centralized “Zero-Queue” Datacenter Network_](http://fastpass.mit.edu/Fastpass-SIGCOMM14-Perry.pdf)_. ACM SIGCOMM, August 2014._

## 3.1.2 以路由器为中心还是以主机为中心

既然资源分配是分布式的，那下一个问题就是：应该在网络内部（即，在路由器或交换机处）还是在网络边缘（即，在主机中，或许作为传输协议的一部分）实现拥塞控制机制。这并非严格的非此即彼的选择。具体的实现两个地方都有涉及，真正的问题在于主要的决策会落在哪里？路由器总是负责确定哪些数据包用来转发，哪些需要被丢弃。但是，路由器该以何种程度与终端主机就有关数据包转发还是丢弃进行交互，以及终端主机该如何理解路由器决策行为，存在各种选择。

一个极端是以路由器为中心。路由器可以允许主机预留容量，然后确保每个流的数据包基于该容量相应地被传送。例如，他们可以通过实施一个信号协议以及Fair Queue来做到这一点，只在当有足够容量时才接受新的数据流，并对管理主机，以确保它们的数据流只使用给它们预留的资源。这对应于一个基于预留的方法，其中的网络可以保证 QoS。但我们认为这个内容超出了本书的讨论范围。

另一个极端是以主机为中心。路由器不提供任何保证，也不提供关于可用容量的明确反馈（当其缓冲区满时会静默丢包），而是由主机负责观察网络状况（例如，他们成功通过网络发送了多少个数据包）并相应地调整其行为。
