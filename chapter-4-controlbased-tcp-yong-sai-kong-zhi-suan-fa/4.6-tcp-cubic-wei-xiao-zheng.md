# 4.6 TCP CUBIC 未校正

到目前为止大家应该已经清楚，拥塞控制算法的核心在于找到合适的向网络发送数据的速率，而这很容易出错。如果发送太少的数据，那网络利用率就比较低，进而导致应用程序性能较差。发送太多的数据，网络又会变得拥塞，最坏情况下会完全堵死。对比这两种情况，发送太多数据更加糟糕，因为拥塞情况下包重传会让问题急剧恶化。前面介绍的集成于 Tahoe，Reno和 NewReno 的 AIMD也表达了这个思想：慢慢的增加窗口大小（加法递增）但是快速的减小窗口（乘法递减），这样才能从线路堵死前恢复过来。但是对于一个高带宽延时乘积的环境中，保守的探测拥塞窗口大小的代价太大了，因为在真正填满线路前，可能需要等待多个 RTT 时间。所以对于如何探测合适的拥塞窗口大小，又有了一些新的思考。

一种称为 Binary Increase Congestion Control（BIC）的方法指出，拥塞窗口在某些时候可以快速加大，在某些时候又需要慢慢的加大。TCP Reno 在最开始会指数级增加窗口大小，之后再突然的转变成线性增加，而 BIC 选择通过二分查找的方法来找到“正确”的窗口大小。在丢包之后，拥塞窗口按照乘法因子β进行缩减。每当一个窗口内的 packet 都成功发送了，拥塞窗口会变成当前值和触发拥塞时的旧值的中点。这样的话，拥塞窗口渐进的向旧的拥塞窗口靠近：开始很快，然后很慢。（极端情况下，窗口值永远达不到原来的值，详见[Zeno 悖论](https://en.wikipedia.org/wiki/Zeno's\_paradoxes)。所以当窗口达到特定的阈值时，它就会被设置为原来的值）

此时，如果没有拥塞，我们可以直到网络状况已经发生变化（注，已经变好），并且可以尝试探测新的拥塞窗口大小。BIC 算法开始会慢慢探测，后面逐渐变快。你可以从图 28 大致看到 BIC 是如何增加其窗口。其中 Wmax是上次丢包前旧的拥塞窗口。

<figure><img src="../.gitbook/assets/image (13).png" alt=""><figcaption><p>图 28：CUBIC 算法中拥塞窗口与时间的关系曲线</p></figcaption></figure>

BIC 最终进化成了一个新的变种，CUBIC。CUBIC 如今是 Linux 中的默认拥塞控制算法。相比 BIC，CUBIC 有很多改进：

* 用一个平滑的 cubic 函数（注，立方函数）来替代 BIC 中的分段线性函数。
* 根据上一次拥塞事件（例如，收到一个重复 ACK）流逝的时间来调整拥塞窗口，而不是像 BIC 一样根据收到 ACK 来调节。因为 ACK 受 RTT 影响而短 RTT 连接可以更加频繁的收到 ACK，CUBIC 的这个改进可以使得长 RTT 的连接更公平的与短 RTT 的连接进行竞争（注，假设你从电脑同时下载同城市的文件和下载跨国服务器的文件，当发生拥塞时，如果采用 BIC 算法，同城市的TCP 连接更快恢复拥塞窗口，会占用更多的带宽）。这是与之前 TCP 版本一个有趣的不同点，在之前的版本中，短 RTT 的 TCP 连接在共享一个瓶颈链路时明显会有优势。

图 28 中展示的立方函数有三个阶段：快速增加，平稳调节，继续快速增加。这里的初始目标 Wmax就是上次拥塞事件前的拥塞窗口大小。你可以看到窗口大小开始增长的很快，但是当接近 Wmax 时就慢下来了；之后当接近 Wmax 时，窗口的增长会小心的增长；最后会尝试探测一个新的 Wmax。

刚刚说到，CUBIC 会基于上次拥塞事件过去的时间来计算拥塞窗口（CongestionWindow）的大小。

<figure><img src="../.gitbook/assets/image (14).png" alt="" width="373"><figcaption></figcaption></figure>

其中

<figure><img src="../.gitbook/assets/image (15).png" alt="" width="212"><figcaption></figcaption></figure>

C 是缩放比例，β时乘法递减因子。CUBIC 将β设置成0.7，而不是其他 TCP 版本中的 0.5。通过图 28 可以看出，CUBIC会从[凹函数](https://en.wikipedia.org/wiki/Concave\_function)转变成[凸函数](https://en.wikipedia.org/wiki/Convex\_function)，而之前 TCP 版本中增加窗口只有凸函数。

有趣的是，相比之前版本的 TCP，CUBIC在不同的场景下要么更加激进，要么更不激进。短 RTT 的TCP Reno 连接更可能获得瓶颈链路的带宽，所以 CUBIC 引入了一种“TCP 友好”的模式使其变得与 TCP Reno 一样激进（注，我也没懂这句话想表达什么）。但是在其他清况下，尤其是在高带宽延时网络中，CUBIC 更可能获得瓶颈链路更多的带宽，因为 CUBIC 更快的增加其窗口大小。这让我们重新思考 3.3 中讨论过的，“公平性”是否是一个正确的设计目标。最终，CUBIC 被充分的分析，并且在多个场景展示了很好的性能的同时也没有带来不必要的破坏，所以它已经被广发的部署。

_继续阅读：S. Ha, I. Rhee, and L. Xu._ [_CUBIC: a New TCP-friendly High-speed TCP Variant_](https://www.cs.princeton.edu/courses/archive/fall16/cos561/papers/Cubic08.pdf)_. ACM SIGOPS Operating Systems Review, July 2008_\
